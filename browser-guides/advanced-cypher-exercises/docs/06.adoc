= Exercise 6
:icons: font

== Exercise 6: Loading denormalized data (Preparations)

*Verify that your Neo4j Browser session has access to the APOC library by executing the Cypher below*:

[source, cypher]
----
CALL dbms.procedures()
YIELD name
WHERE name STARTS WITH 'apoc.'
RETURN name ORDER BY name ASC
----

If this code does not return the list of APOC procedures, then you must ensure that the APOC library is available by installing the plugin (Neo4j Desktop) and restarting the database as follows:

. Make sure Neo4j Desktop is online.
. In Neo4j Desktop for the project you are working with, click  *Add Plugin*.
. Select the install button for APOC.
. Click the Install button.
. Close the Add Plugin window.
. Start or restart the database.

== Exercise 6: Loading denormalized data (Overview)

In this exercise, you will first remove all data and indexes from the database so you can start fresh, then  you will load denormalized data into the database.

* *Exercise 6.1*: Remove all nodes, relationships, and indexes from the database.
* *Exercise 6.2*: Determine how large the dataset is that you will be loading.
* *Exercise 6.3*: Examine the data you will be loading.
* *Exercise 6.4*: Create the constraints.
* *Exercise 6.5*: Load the movie and person data by merging the movie data from the row and then the person data.
* *Exercise 6.6*: Remove all nodes and relationships from the database and then profile the same load.
* *Exercise 6.7*: Remove all nodes and relationships from the database.
* *Exercise 6.8*: Load and merge the movie data while collecting the person data, then use unwind to merge the person data.
* *Exercise 6.9*: Create the indexes.
* *Exercise 6.10*: Create the `Genre` nodes and `:IS_GENRE` relationships.

Go to the next page to start this exercise.

== Exercise 6.1: Remove all nodes, relationships, and indexes from the database. (Instructions)

*To start with a database that contains no data or indexes, run this code just like you did in the previous exercise:*

[source, cypher]
----
// Remove all indexes and constraints
CALL apoc.schema.assert({},{},true);
// Remove all nodes/relationships
MATCH (n:Person) DETACH DELETE n;
MATCH (n:Director) DETACH DELETE n;
MATCH (n:Actor) DETACH DELETE n;
MATCH (n:Movie) DETACH DELETE n;
MATCH (n:Genre) DETACH DELETE n
----

== Exercise 6.1: Remove all nodes, relationships, and indexes from the database. (Solution)

*To start with a database that contains no data or indexes, run this code just like you did in the previous exercise:*

[source, cypher]
----
// Remove all indexes and constraints
CALL apoc.schema.assert({},{},true);
// Remove all nodes/relationships
MATCH (n:Person) DETACH DELETE n;
MATCH (n:Director) DETACH DELETE n;
MATCH (n:Actor) DETACH DELETE n;
MATCH (n:Movie) DETACH DELETE n;
MATCH (n:Genre) DETACH DELETE n
----

The results returned should look like this:

[.thumb]
image::EX6.1.png[EX6.1,width=600]

The database should have no nodes and relationships.

== Exercise 6.2: Determine how large the dataset is that you will be loading. (Instructions)

The dataset containing the denormalized data is found here:

https://data.neo4j.com/advanced-cypher/movies2.csv

*Write Cypher code to return the number of lines in this file.*

== Exercise 6.2: Determine how large the dataset is that you will be loading. (Solution)

The dataset containing the denormalized data is found here:

https://data.neo4j.com/advanced-cypher/movies2.csv

*Write Cypher code to return the number of lines in this file.*

Here is the solution code:

[source, cypher]
----
LOAD CSV WITH HEADERS FROM
     'https://data.neo4j.com/advanced-cypher/movies2.csv' AS rows
RETURN count(rows) as FileRows
----

The results returned should look like this:

[.thumb]
image::EX6.2.png[EX6.2,width=600]

The number of rows in this file is < 100K so we should not need any special loading options (like `USING PERIODIC COMMIT`).

== Exercise 6.3: Examine the data you will be loading. (Instructions)

Since this is denormalized data, you will need to examine more rows to understand how the data has been normalized.

*Write a query to return the first 50 rows of the CSV file. Make a note of the header names and if IDs are being used to uniquely identify people and movies.*

== Exercise 6.3: Examine the data you will be loading. (Solution)

Since this is denormalized data, you will need to examine more rows to understand how the data has been normalized.

*Write a query to return the first 50 rows of the CSV file. Make a note of the header names and if IDs are being used to uniquely identify people and movies.*

Here is the solution code:

[source, cypher]
----
LOAD CSV WITH HEADERS FROM
     'https://data.neo4j.com/advanced-cypher/movies2.csv' AS rows
RETURN rows LIMIT 50
----

The results should be:

[.thumb]
image::EX6.3.png[EX6.3,width=600]

Notice that each row has movie data and person data. Each row uses a `movieId` and `personId` to uniquely identify a movie or person. A row also has a field, `personType`, where the field will either have a value, "ACTOR" or a value, "DIRECTOR".

== Exercise 6.4: Create the constraints. (Instructions)

The *movies2.csv* fields will be mapped to `Movie` and `Person` node properties as follows:

For `Movie` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|movieId
|id
|title
|title
|avgVote
|avgVote
|releaseYear
|releaseYear
|genres
|genres
|===

*Note*: The tagline data will not be loaded.

For `Person` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|personId
|id
|name
|name
|birthYear
|born
|deathYear
|died
|===

*To improve loading when nodes are created using `MERGE`, add uniqueness constraints as follows, just as you did for the normalized data:*

* *Uniqueness constraint on the `id` property of a `Movie` node.*
* *Uniqueness constraint on the `id` property of a `Person` node.*

== Exercise 6.4: Create the constraints. (Solution)

The *movies2.csv* fields will be mapped to `Movie` and `Person` node properties as follows:

For `Movie` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|movieId
|id
|title
|title
|avgVote
|avgVote
|releaseYear
|releaseYear
|genres
|genres
|===

*Note*: The tagline data will not be loaded.

For `Person` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|personId
|id
|name
|name
|birthYear
|born
|deathYear
|died
|===

*To improve loading when nodes are created using `MERGE`, add uniqueness constraints as follows, just as you did for the normalized data:*

* *Uniqueness constraint on the `id` property of a `Movie` node.*
* *Uniqueness constraint on the `id` property of a `Person` node.*

Here is the solution code:

[source, cypher]
----
CREATE CONSTRAINT ON (m:Movie)
ASSERT m.id IS UNIQUE;

CREATE CONSTRAINT ON (p:Person)
ASSERT p.id IS UNIQUE
----

The results returned should look like this:

[.thumb]
image::EX6.4.png[EX6.4,width=600]

== Exercise 6.5: Load the movie and person data by merging the movie data from the row and then the person data. (Instructions)

The *movies2.csv* fields will be mapped to `Movie` and `Person` node properties as follows:

For `Movie` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|movieId
|id
|title
|title
|avgVote
|avgVote
|releaseYear
|releaseYear
|genres
|genres
|===

*Note*: The tagline data will not be loaded.

For `Person` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|personId
|id
|name
|name
|birthYear
|born
|deathYear
|died
|===


*Load the movies2.csv file to:*

. *Use `MERGE` to create the `Movie` node.*
. *Use `MERGE` to create the `Person` node.*
. *Use conditional processing to create the relationships, `:DIRECTED` and `:ACTED_IN` (using apoc.do.when).*

== Exercise 6.5: Load the movie and person data by merging the movie data from the row and then the person data. (Solution)

The *movies2.csv* fields will be mapped to `Movie` and `Person` node properties as follows:

For `Movie` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|movieId
|id
|title
|title
|avgVote
|avgVote
|releaseYear
|releaseYear
|genres
|genres
|===

*Note*: The tagline data will not be loaded.

For `Person` nodes:

[cols="20,80",frame=none, stripes=none]
|===
|*row field*
|*property*
|personId
|id
|name
|name
|birthYear
|born
|deathYear
|died
|===

*Load the movies2.csv file to:*

. *Use `MERGE` to create the `Movie` node.*
. *Use `MERGE` to create the `Person` node.*
. *Use conditional processing to create the relationships, `:DIRECTED` and `:ACTED_IN` (using apoc.do.when).*

Here is the solution code:

[source, cypher]
----
LOAD CSV WITH HEADERS FROM 'https://data.neo4j.com/advanced-cypher/movies2.csv' AS row
MERGE (m:Movie {id: toInteger(row.movieId)})
   ON CREATE SET m.title=row.title, m.avgVote=toFloat(row.avgVote),
      m.releaseYear=toInteger(row.releaseYear), m.genres=split(row.genres,":")
MERGE (p:Person {id: toInteger(row.personId)})
   ON CREATE SET p.name = row.name, p.born = toInteger(row.birthYear),
      p.died = toInteger(row.deathYear)
WITH row, m, p
CALL apoc.do.when(row.personType = 'ACTOR',
     "MERGE (p)-[:ACTED_IN {roles: split(coalesce(row.characters,''), ':')}]->(m)
          ON CREATE SET p:Actor",
     "MERGE (p)-[:DIRECTED]->(m)
          ON CREATE SET p:Director",
      {row:row, m:m, p:p}) YIELD value AS value
SET p:Person  // cannot end query with APOC call
----

The results returned should look like this:

[.thumb]
image::EX6.5.png[EX6.5,width=700]

== Exercise 6.6: Remove all nodes and relationships from the database and then profile the same load. (Instructions)

*1. Execute this code to remove all nodes and relationships in the database:*

[source, cypher]
----
MATCH (n:Person) DETACH DELETE n;

MATCH (n:Director) DETACH DELETE n;

MATCH (n:Actor) DETACH DELETE n;

MATCH (n:Movie) DETACH DELETE n
----

*2. Profile the previously executed load.*

== Exercise 6.6: Remove all nodes and relationships from the database and then profile the same load. (Solution)

*1. Execute this code to remove all nodes and relationships in the database:*

[source, cypher]
----
MATCH (n:Person) DETACH DELETE n;

MATCH (n:Director) DETACH DELETE n;

MATCH (n:Actor) DETACH DELETE n;

MATCH (n:Movie) DETACH DELETE n
----

*2. Profile the previously executed load.*

[source, cypher]
----
PROFILE LOAD CSV WITH HEADERS FROM 'https://data.neo4j.com/advanced-cypher/movies2.csv' AS row
MERGE (m:Movie {id: toInteger(row.movieId)})
   ON CREATE SET m.title=row.title, m.avgVote=toFloat(row.avgVote),
      m.releaseYear=toInteger(row.releaseYear), m.genres=split(row.genres,":")
MERGE (p:Person {id: toInteger(row.personId)})
   ON CREATE SET p.name = row.name, p.born = toInteger(row.birthYear),
      p.died = toInteger(row.deathYear)
WITH row, m, p
CALL apoc.do.when(row.personType = 'ACTOR',
     "MERGE (p)-[:ACTED_IN {roles: split(coalesce(row.characters,''), ':')}]->(m)
          ON CREATE SET p:Actor",
     "MERGE (p)-[:DIRECTED]->(m)
          ON CREATE SET p:Director",
      {row:row, m:m, p:p}) YIELD value AS value
SET p:Person  // cannot end query with APOC call
----

The results returned should look like this:

[.thumb]
image::EX6.6.png[EX6.6,width=900]

This load required 347,703 DB hits.

== Exercise 6.7: Remove all nodes and relationships from the database. (Instructions)

*Next, you will try another alternative for loading the denormalized data so you should execute this code the remove all existing nodes and relationships:*

[source, cypher]
----
// Remove all nodes/relationships
MATCH (n:Person) DETACH DELETE n;
MATCH (n:Director) DETACH DELETE n;
MATCH (n:Actor) DETACH DELETE n;
MATCH (n:Movie) DETACH DELETE n
----

== Exercise 6.7: Remove all nodes and relationships from the database. (Solution)

*Next, you will try another alternative for loading the denormalized data so you should execute this code the remove all existing nodes and relationships:*

[source, cypher]
----
// Remove all nodes/relationships
MATCH (n:Person) DETACH DELETE n;
MATCH (n:Director) DETACH DELETE n;
MATCH (n:Actor) DETACH DELETE n;
MATCH (n:Movie) DETACH DELETE n
----

The results returned should look like this:

[.thumb]
image::EX6.7.png[EX6.7,width=700]

The database should have no nodes and relationships.

== Exercise 6.8: Load and merge the movie data while collecting the person data, then use unwind to merge the person data. (Instructions)

*Load the movie data while collecting the person data, then use unwind to merge the person data. Just like you did previously, `CALL apoc.doc.when()` to add the relationships. Profile this load.*

== Exercise 6.8: Load and merge the movie data while collecting the person data, then use unwind to merge the person data. (Solution)

*Load the movie data while collecting the person data, then use unwind to merge the person data. Just like you did previously, `CALL apoc.doc.when()` to add the relationships. Profile this load.*

Here is the solution code:

[source, cypher]
----
PROFILE LOAD CSV WITH HEADERS FROM
     'https://data.neo4j.com/advanced-cypher/movies2.csv' AS row
WITH row.movieId as movieId, row.title as title, row.genres as genres,
toInteger(row.releaseYear) as releaseYear, toFloat(row.avgVote) as avgVote,
collect({id: row.personId, name:row.name, born: toInteger(row.birthYear), died:toInteger(row.deathYear),personType: row.personType, roles: split(coalesce(row.characters,""),':')}) as people
MERGE (m:Movie {id:movieId})
   ON CREATE SET m.title=title, m.avgVote=avgVote,
      m.releaseYear=releaseYear, m.genres=split(genres,":")
WITH *
UNWIND people as person
MERGE (p:Person {id: person.id})
   ON CREATE SET p.name = person.name, p.born = person.born, p.died = person.died
WITH  m, person, p
CALL apoc.do.when(person.personType = 'ACTOR',
     "MERGE (p)-[:ACTED_IN {roles: person.roles}]->(m)
                ON CREATE SET p:Actor",
     "MERGE (p)-[:DIRECTED]->(m)
         ON CREATE SET p:Director",
     {m:m, p:p, person:person}) YIELD value AS value
RETURN count()  // cannot end query with APOC call
----

The results returned should look like this:

[.thumb]
image::EX6.8.png[EX6.8,width=900]

This method of loading the data required 290,026 DB hits, which is better than the previous method. Collecting the results and unwinding them is much more efficient.

== Exercise 6.9: Create the indexes. (Instructions)

*To improve retrieval performance, create indexes as follows, just as you did for the normalized data:*

* *Index on the `name` property of a `Person` node.*
* *Index on the `title` property of a `Movie` node.*


== Exercise 6.9: Create the indexes and constraints. (Solution)

*To improve retrieval performance, create indexes as follows, just as you did for the normalized data:*

* *Index on the `name` property of a `Person` node.*
* *Index on the `title` property of a `Movie` node.*

Here is the solution code:

[source, cypher]
----
CREATE INDEX ON :Person(name);

CREATE INDEX ON :Movie(title)
----

The results returned should look like this:

[.thumb]
image::EX6.9.png[EX6.9,width=600]

== Exercise 6.10: Create the `Genre` nodes and `:IS_GENRE` relationships. (Instructions)

*Just as you did for the load of the normalized data,  create a uniqueness constraint for the `name` property for nodes of type `Genre`.
Then use the data in the graph to create `Genre` nodes from the `Movie` nodes and add the `:IS_GENRE` relationships between `Movie` nodes and `Genre` nodes.
In addition, remove the `genres` property from the `Movie`  nodes.*

== Exercise 6.10: Create the `Genre` nodes and `:IS_GENRE` relationships. (Solution)

*Just as you did for the load of the normalized data,  create a uniqueness constraint for the `name` property for nodes of type `Genre`.
Then use the data in the graph to create `Genre` nodes from the `Movie` nodes and add the `:IS_GENRE` relationships between `Movie` nodes and `Genre` nodes.
In addition, remove the `genres` property from the `Movie`  nodes.*

Here is the solution code:

[source, cypher]
----
CREATE CONSTRAINT ON (g:Genre) ASSERT g.name IS UNIQUE;
MATCH (m:Movie)
UNWIND m.genres as name
WITH DISTINCT name, m
SET m.genres = null
MERGE (g:Genre {name:name})
WITH g, m
MERGE (g)<-[:IS_GENRE]-(m)
----

The results returned should look like this:

[.thumb]
image::EX6.10.png[EX6.10,width=700]

Your database should now be as follows:

[.thumb]
image::EX6.10B.png[EX6.10B,width=300]

== Exercise 6: Taking it further

Perform some queries to become familiar with the newly-loaded data.

== Exercise 6: Loading denormalized data   (Summary)

In this exercise, you have written code to load denormalized data into a graph and also create nodes from data in the graph. You have seen that one way that you can optimize the load is to save the data during one pass into a collection and unwind the data for processing.

ifdef::env-guide[]
pass:a[<a play-topic='{guides}/07.html'>Continue to Exercise 7</a>]
endif::[]
